embedding : 내용의 유사도를 딥러닝을 통해 숫자벡터로 바꾸는 방식.
유사도는 코사인 유사도를 사용.
너무 오래걸림.  
텍스트를 뽑아내고 벡터를 뽑아내는 방식으로 바꾸고 나서 오래걸리게 됨. 
한번에 벡터를 뽑아내게 하면 돌아는 감. 
PCS라고 차원을 줄이는 방식을 사용했는데 효과가 좋지는 않음.
그냥 그래프를 써봐야할 듯.

Jakards : 단어의 합집합 분의 교집합 으로 거리를 측정.
보고서 양식 때문에 아예 글씨 안 쓴 학생들끼리 모여있음.

levenshtein : 편집거리.
얼마나 길게 썼는지가 너무 많이 영향을 줌

LCS : 가장 많이 겹치는 문자열 길이를 뽑아내는 알고리즘.
이건 보고서 양식 때문에 못쓸 것 같음.